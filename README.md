<h1 align="center">OpenAgent</h1>
<p align="center">
  <a href="https://github.com/mrbende?tab=followers" target="_blank">
    <img src="https://img.shields.io/github/followers/mrbende?style=social" alt="Follow on GitHub">
  </a>
  <a href="https://github.com/mrbende/OpenAgent/stargazers" target="_blank">
    <img src="https://img.shields.io/github/stars/mrbende/OpenAgent?style=social" alt="GitHub stars">
  </a>
  <br>
  <a href="https://github.com/mrbende/OpenAgent/commits" target="_blank">
    <img src="https://img.shields.io/github/commit-activity/y/mrbende/OpenAgent" alt="GitHub commits">
  </a>
  <a href="https://github.com/mrbende/OpenAgent/commits" target="_blank">
    <img src="https://img.shields.io/github/last-commit/mrbende/OpenAgent" alt="GitHub last commit">
  </a>
</p>
<p align="center">
  <a href="OpenAgent Logo">
    <img src="https://i.imgur.com/1bPTaJw.png" alt="OpenAgent" width="200" height="200">
  </a>
</p>
<p align="center">Join the community on Discord!</p>
<p align="center">
  <a href="https://discord.gg/ypNKmKa4XW" target="_blank">
    <img src="https://dcbadge.vercel.app/api/server/ypNKmKa4XW" alt="Discord">
  </a>
</p>

---


An open-source initiative dedicated to enhancing the capabilities of Large Language Models to act as autonomous agents.

## Mission

OpenAgent is committed to spearheading the use of Large Language Models (LLMs) as efficient, autonomous agents. We strive to enhance the performance, usability, and adaptability of these models through a collaborative, open-source initiative. We aim to establish a decentralized, open-source, and community-driven agent ecosystem that is independent of proprietary models like OpenAI's GPT-4.

Our vision extends to creating tools that can be widely customized and economically deployed, sparking a new generation of agents capable of addressing a broad spectrum of problems. However, our mission is not only to develop and fine-tune agent-specific LLMs, but also to foster a community of researchers, developers, and enthusiasts who share our vision for the future of autonomous agents. At OpenAgent, we value innovation, continuous improvement, and inclusivity.

## Roadmap

OpenAgent is currently in its early stages. While the initial groundwork has been laid, our community is actively working on fleshing out a comprehensive strategy for the project's future. Our ambitions are high and the journey has just begun, and we're excited to shape the trajectory of this initiative.

A key facet of our early development is the creation of an agent-specific markup language, AgentML. This language is being designed with a special emphasis on maximizing the efficiency and effectiveness of Large Language Models in the realm of autonomous agents.

Upon the completion and stabilization of AgentML, our next focus will be on the collection and synthesis of training data. A robust dataset will enable us to fine-tune LLMs for optimal performance in various agent-based applications.

In terms of the specific models we plan to work with, both MPT-7B and Falcon-40B are being strongly considered. These models are noted for their impressive abilities and potential, making them fitting subjects for our fine-tuning efforts.

As we navigate through the early stages of our journey, we encourage participation and contribution in various forms â€“ from coding to idea sharing and constructive feedback. We envision a future where LLMs play a crucial role in shaping the way we interact with technology and the world. Join us as we collectively push the boundaries of what's possible with LLMs and autonomous agents.

## Resources
* [ðŸ¦œðŸ”— LangChain Structured Chat Agent](https://python.langchain.com/en/latest/modules/agents/agents/examples/structured_chat.html)
* [ðŸ¤— MPT-7B on Hugging Face](https://huggingface.co/mosaicml/mpt-7b)
* [ðŸ¤— Falcon-40B on Hugging Face](https://huggingface.co/tiiuae/falcon-40b)
* [Fine-Tuning MPT-7B](https://www.youtube.com/watch?v=KSlWkrByc0o&t=17s)
* [LoRa for Fine-Tuning](https://bdtechtalks.com/2023/05/22/what-is-lora/)
* [Sophia, a Second-order Optimizer](https://arxiv.org/abs/2305.14342)
* [ðŸ¦œðŸ”— LangChain-Datasets](https://huggingface.co/LangChainDatasets)
